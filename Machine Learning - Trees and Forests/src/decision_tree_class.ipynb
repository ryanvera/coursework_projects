{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used in parsing data and creating decision tree\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "# Used in visualizing the decision tree\n",
    "from sklearn import tree\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Used in hyperparameter optimization (GridSearch)\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of file suffixes\n",
    "dataFileKey = {1: \"c300_d100\", \n",
    "               2: \"c300_d1000\",\n",
    "               3: \"c300_d5000\",\n",
    "               4: \"c500_d100\",\n",
    "               5: \"c500_d1000\",\n",
    "               6: \"c500_d5000\",\n",
    "               7: \"c1000_d100\",\n",
    "               8: \"c1000_d1000\",\n",
    "               9: \"c1000_d5000\",\n",
    "               10: \"c1500_d100\",\n",
    "               11: \"c1500_d1000\",\n",
    "               12: \"c1500_d5000\",\n",
    "               13: \"c1800_d100\",\n",
    "               14: \"c1800_d1000\",\n",
    "               15: \"c1800_d5000\"}\n",
    "\n",
    "# File suffix key number\n",
    "dataFileKeyNum:int = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two section below are responsible for loading the data and splitting it into its approipate variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data sets, all from the same grouping\n",
    "\n",
    "# Training data\n",
    "filePath = \"..\\project2_data\\\\train_\" + dataFileKey[dataFileKeyNum] + \".csv\"\n",
    "trainData = pd.read_csv(filePath, header = None)\n",
    "\n",
    "# Test data\n",
    "filePath = \"..\\project2_data\\\\test_\" + dataFileKey[dataFileKeyNum] + \".csv\"\n",
    "testData = pd.read_csv(filePath, header = None)\n",
    "\n",
    "# Validation data\n",
    "filePath = \"..\\project2_data\\\\valid_\" + dataFileKey[dataFileKeyNum] + \".csv\"\n",
    "validData = pd.read_csv(filePath, header = None)\n",
    "\n",
    "# trainData.head(10)\n",
    "# testData.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data sets into features and classes\n",
    "\n",
    "# Training Data Split\n",
    "trainX = trainData.drop(columns=[trainData.columns[-1]])\n",
    "trainY = trainData.iloc[:, -1:]\n",
    "\n",
    "# Testing Data Split\n",
    "testX = testData.drop(columns=[testData.columns[-1]])\n",
    "testY = testData.iloc[:, -1:]\n",
    "\n",
    "# Validation Data Split\n",
    "validX = validData.drop(columns=[validData.columns[-1]])\n",
    "validY = validData.iloc[:, -1:]\n",
    "\n",
    "# Combine train and validation data\n",
    "combineX = pd.concat([trainX, validX], ignore_index=True)\n",
    "combineY = pd.concat([trainY, validY], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below will create, run, and test the basic decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create decision tree\n",
    "decisionTree = DecisionTreeClassifier()\n",
    "\n",
    "\n",
    "# Train tree on data\n",
    "decisionTree = decisionTree.fit(trainX, trainY)\n",
    "\n",
    "\n",
    "# Test decision tree\n",
    "predictions = decisionTree.predict(validX)\n",
    "\n",
    "\n",
    "# Print accuracy\n",
    "print(\"Validation Data Metrics\")\n",
    "print(\"Accuracy: \", metrics.accuracy_score(validY, predictions))\n",
    "print(\"F1 Score: \" + str(metrics.f1_score(validY, predictions)))\n",
    "print(\"Precision: \" + str(metrics.precision_score(validY, predictions)))\n",
    "\n",
    "# Visualize tree\n",
    "# fig = plt.figure(figsize=(50, 50))\n",
    "# _ = tree.plot_tree(decisionTree, feature_names=trainX.columns, class_names=[\"0\", \"1\"], filled = True)\n",
    "# fig.savefig(\"../decision_tree.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below will create, run, test, and optimize a decision tree classifier using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearch Tree\n",
      "Best params: {'criterion': 'gini', 'max_depth': 6, 'random_state': 7, 'splitter': 'random'}\n",
      "Best score: 0.615\n",
      "----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Create GridSearch hyper-parameters\n",
    "grid_params = {\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_depth\": range(5, 15),\n",
    "    \"random_state\": range(5, 10),\n",
    "    \"splitter\": [\"best\", \"random\"]\n",
    "}\n",
    "\n",
    "# Create decision tree\n",
    "decisionTree = DecisionTreeClassifier()\n",
    "\n",
    "# Init GridSearch and train model\n",
    "gridTree = GridSearchCV(decisionTree, param_grid=grid_params, cv=5, verbose=0, n_jobs=-1)\n",
    "gridTree.fit(trainX, trainY)\n",
    "\n",
    "\n",
    "\n",
    "# Print report\n",
    "print(\"GridSearch Tree\")\n",
    "print(\"Best params: \" + str(gridTree.best_params_))\n",
    "print(\"Best score: \" + str(gridTree.best_score_))\n",
    "print(\"----------------------------------------------------------\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below creates a new tree with the best parameters. Then it is fitted to the combination of training and validation data. Testing is performed on the test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-trained tree\n",
      "Accuracy:  0.66\n",
      "F1 Score: 0.6761904761904762\n",
      "Precision: 0.6454545454545455\n"
     ]
    }
   ],
   "source": [
    "# Create another tree with the best parameters\n",
    "bestTree = gridTree.best_estimator_\n",
    "bestTree.fit(combineX, combineY)\n",
    "\n",
    "# Print report\n",
    "print(\"Re-trained tree\")\n",
    "predictions = bestTree.predict(testX)\n",
    "\n",
    "\n",
    "print(\"Accuracy: \", metrics.accuracy_score(testY, predictions))\n",
    "print(\"F1 Score: \" + str(metrics.f1_score(testY, predictions)))\n",
    "print(\"Precision: \" + str(metrics.precision_score(testY, predictions)))\n",
    "\n",
    "# print(metrics.classification_report(validY, predictions))\n",
    "# print(metrics.confusion_matrix(validY, predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
